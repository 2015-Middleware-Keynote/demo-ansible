# vim: set ft=ansible:
---
- include: cloudformation_setup.yml

- include: group_setup.yml

# The master DNS entry is used because it's valuable to have an easy hostname to SSH into
- name: Configure master DNS entry
  hosts: project_master
  gather_facts: yes
  become: no
  tasks:
  - name: Route53 entry for master
    route53:
      command: create
      zone: "{{ r53_zone }}"
      record: "openshift-master.{{ r53_host_zone }}"
      ttl: 60
      type: A
      value: "{{ hostvars[groups['tag_openshift-demo-' ~ cluster_id ~ '-host-type_master'].0]['ec2_ip_address'] }}"
      overwrite: yes
    delegate_to: localhost
    
# Register hosts via RHSM (as required) and configure repos
- include: subscriptions_and_repos.yml

- name: Miscellaneous Host Configuration
  hosts: cluster_hosts
  tasks:
  - name: Create /etc/origin directory
    command: mkdir -p /etc/origin

  - name: Create aws.conf ini file
    ini_file:
      dest: /etc/origin/aws.conf
      section: Global
      option: Zone
      value: "{{ ec2_placement }}"

  - name: Update current package set
    yum:
      name: '*'
      state: latest

  # ultimately we are setting the kube resolver as the first resolver
  # so we need to turn off DNS checking in SSHD otherwise connections
  # take a very long time
  - name: Turn off DNS checking in SSHD
    lineinfile:
      dest: /etc/ssh/sshd_config
      regexp: ".*UseDNS.*"
      line: "UseDNS no"
    register: sshd_config_result

  - name: Restart SSHD
    service: 
      name: sshd
      state: restarted
    when: sshd_config_result | changed

# Configure the instances
- include: ../../openshift-ansible/playbooks/byo/openshift-cluster/config.yml
  vars_files:
  - ../../../../demo-ansible/playbooks/vars.yml
  vars:
    deployment_type: "{{ deployment_type }}"
    openshift_cluster_id: "{{ cluster_id }}"
    openshift_debug_level: "{{ debug_level }}"
    openshift_node_debug_level: "{{ node_debug_level | default(debug_level, true) }}"
    osm_controller_args:
      cloud-provider:
      - "aws"
      cloud-config:
      - "/etc/origin/aws.conf"
    osm_api_server_args:
      cloud-provider:
      - "aws"
      cloud-config:
      - "/etc/origin/aws.conf"
    openshift_node_kubelet_args:
      max-pods:
      - "100"
      cloud-provider:
      - "aws"
      cloud-config:
      - "/etc/origin/aws.conf"
    openshift_master_debug_level: "{{ master_debug_level | default(debug_level, true) }}"
    openshift_master_access_token_max_seconds: 2419200
    openshift_master_identity_providers: "{{ identity_providers }}"
    openshift_master_api_port: "{{ console_port }}"
    openshift_master_console_port: "{{ console_port }}"
    openshift_package_version: 3.1.1.6
    openshift_master_logging_public_url: "https://kibana.{{ r53_wildcard_zone }}"
    openshift_master_metrics_public_url: "https://metrics.{{ r53_wildcard_zone }}/hawkular/metrics"
    osm_cluster_network_cidr: 10.0.0.0/8
    osm_host_subnet_length: 16
    osm_default_subdomain: "{{ r53_wildcard_zone }}"
    osm_default_node_selector: "env=demo"
    osm_use_cockpit: false
    openshift_master_cluster_method: native
    openshift_master_cluster_hostname: openshift.internal.{{ r53_host_zone }}
    openshift_master_cluster_public_hostname: openshift.{{ r53_host_zone }}
    os_firewall_enabled: False

# Router, Registry, internal users and projects, priming
- include: post_setup.yml
