# vim: set ft=ansible:
---
- name: Setup groups
  hosts: localhost
  gather_facts: no
  connection: local
  become: no
  tasks:
  - include: tasks/group_setup.yml

- name: Gather environment information
  hosts: project_master
  tasks:
  - name: Determine kubernetes service IP
    shell: "oc get service kubernetes -o yaml | grep clusterIP | awk '{print $2}'"
    register: kube_svc_ip_local
  - name: Set the kubernetes service IP fact
    set_fact:
      kube_svc_ip: "{{ kube_svc_ip_local.stdout }}"

- name: Node post configuration
  hosts: nodes
  vars_files:
  - vars.yml
  tasks:
  - name: pre-pull images
    command: "docker pull {{ item }}"
    with_items: preload_images

- name: User creation
  hosts: masters
  vars_files:
  - vars.yml
  tasks:
  - name: Create the default users
    command: "htpasswd -b /etc/origin/master/htpasswd {{ item.user }} {{ default_password }}"
    with_items: users

- name: Configure default project
  hosts: project_master
  vars_files:
  - vars.yml
  vars:
    default_context: 'default/openshift-internal-{{ r53_host_zone  | regex_replace("\.", "-") }}:{{ api_port }}/system:admin'
  tasks:
  - name: Change the oc context
    command: "oc config use-context {{ default_context }}"

  - name: Switch to default project
    command: oc project default

  - name: Set nodeselector for the default project to be region=infra
    shell: "oc get namespace default -o yaml  | sed -e '/  annotations:/a\\    openshift.io/node-selector: region=infra' | oc replace -f -"

- name: Installation and Configuration of Router
  hosts: project_master
  vars_files:
  - vars.yml
  vars:
    default_context: 'default/openshift-internal-{{ r53_host_zone  | regex_replace("\.", "-") }}:{{ api_port }}/system:admin'
  tasks:
  - name: Change the oc context
    command: "oc config use-context {{ default_context }}"

  - name: Switch to default project
    command: oc project default

  - name: Verify whether a router exists or not
    command: oadm router --dry-run --service-account=router
    register: router_out
    ignore_errors: true

  - name: Create router cert temporary directory
    file:
      dest: "~{{ ansible_ssh_user }}/router_certs"
      state: directory
    when: router_out | failed

  - name: Generate router certificate files
    command: "oadm create-server-cert --signer-cert=/etc/origin/master/ca.crt --signer-key=/etc/origin/master/ca.key --signer-serial=/etc/origin/master/ca.serial.txt --hostnames='*.{{ r53_wildcard_zone }}' --cert={{ r53_wildcard_zone }}.crt --key={{ r53_wildcard_zone }}.key"
    when: router_out | failed

  - name: Assemble router PEM
    assemble:
      dest: "~{{ ansible_ssh_user }}/{{ r53_wildcard_zone }}.pem"
      src: "~{{ ansible_ssh_user }}/router_certs"
    when: router_out | failed

  - name: Install router
    command: "oadm router --default-cert={{ r53_wildcard_zone }}.pem --credentials=/etc/origin/master/openshift-router.kubeconfig --service-account=router --images='{{ router_image_url }}'"
    when: router_out | failed

  # we should probably do some kind of actual check for router deployment
  - name: Wait for router to deploy
    pause:
      seconds: 10

  - name: Scale router
    command: "oc scale --replicas={{ num_infra_nodes }} dc router"
    when: router_out | failed

# Using EBS storage with OpenShift requires that the systems
# know the EC2 credentials in order to manipulate the EBS volumes.
# masters require the keys in /etc/sysconfig/atomic-openshift-master
- name: Set up master EC2 credentials
  hosts: masters
  gather_facts: no
  vars_files:
  - vars.yml
  tasks:
  - name: Write EC2 key ID to /etc/sysconfig/atomic-openshift-master
    lineinfile:
      dest: /etc/sysconfig/atomic-openshift-master
      insertafter: EOF
      line: "AWS_ACCESS_KEY_ID={{ lookup('env','AWS_ACCESS_KEY_ID') }}"
      regexp: '^AWS_ACCESS_KEY_ID=.*'
    register: master_id_result

  - name: Write EC2 secret key to /etc/sysconfig/atomic-openshift-master
    lineinfile:
      dest: /etc/sysconfig/atomic-openshift-master
      insertafter: EOF
      line: "AWS_SECRET_ACCESS_KEY={{ lookup('env','AWS_SECRET_ACCESS_KEY') }}"
      regexp: '^AWS_SECRET_ACCESS_KEY=.*'
    register: master_key_result

  - name: Restart atomic-openshift-master-controllers service
    service: 
      name: atomic-openshift-master-controllers
      state: restarted
    when: (master_id_result | changed) or (master_key_result | changed)

# Using EBS storage with OpenShift requires that the systems
# know the EC2 credentials in order to manipulate the EBS volumes.
# nodes require the keys in /etc/sysconfig/atomic-openshift-node
- name: Set up node EC2 credentials
  hosts: nodes
  gather_facts: no
  vars_files:
  - vars.yml
  tasks:
  - name: Write EC2 key ID to /etc/sysconfig/atomic-openshift-node
    lineinfile:
      dest: /etc/sysconfig/atomic-openshift-node
      insertafter: EOF
      line: "AWS_ACCESS_KEY_ID={{ lookup('env','AWS_ACCESS_KEY_ID') }}"
      regexp: '^AWS_ACCESS_KEY_ID=.*'
    register: node_id_result

  - name: Write EC2 secret key to /etc/sysconfig/atomic-openshift-node
    lineinfile:
      dest: /etc/sysconfig/atomic-openshift-node
      insertafter: EOF
      line: "AWS_SECRET_ACCESS_KEY={{ lookup('env','AWS_SECRET_ACCESS_KEY') }}"
      regexp: '^AWS_SECRET_ACCESS_KEY=.*'
    register: node_key_result

  - name: Restart atomic-openshift-node service
    service: 
      name: atomic-openshift-node
      state: restarted
    when: (node_id_result | changed) or (node_key_result | changed)

- name: Installation and Configuration of Registry
  hosts: project_master
  gather_facts: no
  vars_files:
  - vars.yml
  vars:
    default_context: 'default/openshift-internal-{{ r53_host_zone  | regex_replace("\.", "-") }}:{{ api_port }}/system:admin'
  tasks:

  # make sure that we are using the default user (system:admin) and the default project
  - name: Change the oc context
    command: "oc config use-context {{ default_context }}"
  
  - name: Switch to default project
    command: oc project default

  - name: Check whether a registry exists or not
    command: oadm registry --dry-run
    register: registry_out
    ignore_errors: true

  - name: Install registry
    command: "oadm registry --credentials=/etc/origin/master/openshift-registry.kubeconfig --images='{{ registry_image_url }}'"
    when: registry_out | failed

  # we use a template to then lay down YAML to create the PV
  # this sets facts that are then consumed in the template
  - name: Set the facts for the registry PV template
    set_fact:
      pv_name: "registry-pv"
      capacity: "50"
      volid: "{{ hostvars['localhost']['registry_volume'] }}"
      access_mode: "ReadWriteMany"
      
  - name: Create a YAML file for the PV for the Registry volume
    template:
      src: templates/pv.yaml.j2
      dest: /root/registry-pv.yaml

  - name: Check for registry PV
    command: oc get pv "{{ pv_name }}"
    register: registry_pv_out
    ignore_errors: true

  # as before
  - name: Set the facts for the registry PVC template
    set_fact:
      claim_name: "registry-pvc"
      capacity: "50"
      access_mode: "ReadWriteMany"
      
  - name: Check for registry PVC
    command: oc get pvc "{{ claim_name }}"
    register: registry_pvc_out
    ignore_errors: true

  - name: Create a YAML file for the PVC for the Registry volume
    template:
      src: templates/pvc.yaml.j2
      dest: /root/registry-pvc.yaml

  - name: Create PV from YAML for registry EBS volume
    command: oc create -f /root/registry-pv.yaml
    when: registry_pv_out | failed

  - name: Create PVC from YAML for registry EBS volume
    command: oc create -f /root/registry-pvc.yaml
    when: registry_pvc_out | failed

  - name: Check if registry is still using empty directory
    command: oc volume dc/docker-registry
    register: registry_dc_out

  - name: Attach volume to registry DC
    command: >
      oc volume dc/docker-registry --add --overwrite -t persistentVolumeClaim
      --claim-name=registry-pvc --name=registry-storage
    #debug: msg="Should see this this time"
    when: "'empty directory' in registry_dc_out.stdout"

  - name: Check if fsGroup is set in registry DC
    shell: "oc get dc/docker-registry -o yaml | grep fsGroup"
    register: fsgroup_out
    ignore_errors: true

  - name: Determine default project supplemental group
    command: oc get project default -o json
    register: default_project_out 
    when: fsgroup_out | failed

  - name: Process the default project json into a fact
    set_fact:
      default_project_json: "{{ default_project_out.stdout | from_json }}"
    when: fsgroup_out | failed

  - name: Patch the docker registry DC with the fsGroup
    command: oc patch dc/docker-registry -p '{"spec":{"template":{"spec":{"securityContext":{"fsGroup":{{ default_project_json["metadata"]["annotations"]["openshift.io/sa.scc.supplemental-groups"].split("/").0 }}}}}}}'
    when: fsgroup_out | failed

- name: Demonstration project configuration
  hosts: project_master
  vars:
    default_context: 'default/openshift-internal-{{ r53_host_zone  | regex_replace("\.", "-") }}:{{ api_port }}/system:admin'
  vars_files:
  - vars.yml
  tasks:
  - name: Find current projects list
    command: oc get projects
    register: projects

  - name: Create projects for internal users
    command: "oadm new-project {{ item.project }} --display-name='{{ item.project.title() }}' --node-selector='region={{ item.project }}' --admin='{{ item.user }}'"
    when: item.project not in projects.stdout
    with_items: users

  - name: Switch to default project
    command: oc project default

  - name: Retrieve hexboard deployment configurations
    command: oc get dc -n {{ hexboard.namespace }}
    register: dcs_out
    failed_when: "hexboard.name not in dcs_out"
    ignore_errors: true

  - name: Login as the demo user
    command: oc login -u {{ users.0.user }} -p {{ default_password }} --certificate-authority=/etc/origin/master/ca.crt
    when: dcs_out | failed

  - name: "Get the demo user's token"
    script: files/get_token.sh
    register: auth_token
    when: dcs_out | failed

  - name: Set the token as a fact
    set_fact:
      access_token: "{{ auth_token.stdout }}"
    when: dcs_out | failed

  - name: Switch to the hexboard project
    command: oc project {{ hexboard.namespace }}
    when: dcs_out | failed

  - name: Install the hexboard template file on the master
    template:
      dest: /root/hexboard_template.json
      src: templates/hexboard_template.json.j2
    when: dcs_out | failed

  - name: Create the objects in the hexboard template
    command: oc create -f /root/hexboard_template.json
    when: dcs_out | failed
    ignore_errors: true

  - name: Start the hexboard build
    command: oc start-build {{ hexboard.name }}
    when: dcs_out | failed

  - name: Change the oc context
    command: "oc config use-context {{ default_context }}"
    when: dcs_out | failed
